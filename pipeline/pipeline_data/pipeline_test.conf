[default]

#
# ID is used to identify pipeline to third parties, e.g. fluentd tag
# and prometheus instance
id = pipeline
metamonitoring_prometheus_resource = /metrics
metamonitoring_prometheus_server = :8888

[myrouters]
type = tcp
encap = st
stage = xport_input
listen = :5556
logdata = on

[myotherrouters]
type = tcp
encap = st
stage = xport_input
listen = :5557
logdata = on

# [mymdtrouter]
# stage = xport_input
# type = grpc
# encap = gpb
# server = 192.168.123.1:56789
# tls = false
# tls_pem = ca.pem
# tls_servername = tlsservername
# subscriptions = genericstats,datarates
# logdata = on

[mykafka]
type = kafka
key = path_and_id
stage = xport_output
brokers = localhost:9092
topic = testtopic
datachanneldepth = 1000
logdata = on

[kafkaconsumer]
type = kafka
key = path_and_id
stage = xport_input
brokers = localhost:9092
topic = consumertopic3
consumergroup = mycollectors
encoding = json
logdata = on

[mykafka2]
type = kafka
key = path_and_id
stage = xport_output
brokers = localhost:9092
topic = consumertopic3
datachanneldepth = 1000
encoding = json
logdata = on

[inspector]
type = tap
stage = xport_output
datachanneldepth = 1000
file = dump.txt
#countonly = true

[inspector1]
type = tap
stage = xport_output
datachanneldepth = 1000
file = dump1.txt
countonly = true

[mymetrics]
stage = xport_output
type = metrics
output = prometheus
file = metrics.json
datachanneldepth = 1000
pushgw = localhost:9091
workers = 1
jobname = telemetry

[mymetricstest]
stage = xport_output
type = metrics
output = test
file = metrics.json
datachanneldepth = 1000

[mygrpcout]
type = grpc
stage = xport_output
encoding = json
listen = localhost:5959
logdata = on
datachanneldepth = 1000

[mygrpcoutnolisten]
type = grpc
stage = xport_output
encoding = json
logdata = on

[mygrpcoutbadencoding]
type = grpc
stage = xport_output
encoding = gibberish
listen = localhost:5959
# logdata = on

[templatetest]
stage = xport_output
type = tap
file = dumpfiltererd.txt
encoding = template
template = filter_test.json
datachanneldepth = 1000

[udpinnolisten]
type = udp
stage = xport_input
rxbuf = 25165824
#logdata = on

[udpinbadlisten]
type = udp
stage = xport_input
listen = localhostuBAD,BAD,BAD:5958
rxbuf = 25165824
#logdata = on

[udpin]
type = udp
stage = xport_input
listen = localhost:5958
rxbuf = 25165824
logdata = on

[replay_bin_archive]
stage = xport_input
type = replay
file = mdt_msg_samples/dump.bin
delayusec = 100000
loop=true
logdata = on

[tap_out_bin_hexdump]
stage = xport_output
type = tap
encoding = gpb
file = mdt_msg_samples/hexdump.bin
datachanneldepth = 1000

[kafkaAout]
type = kafka
key = path_and_id
stage = xport_output
brokers = localhost:9092
topic_metadata_template = topic_template_testA.txt
encoding = json
datachanneldepth = 1000
required_acks = none

[kafkaAin]
type = kafka
key = path_and_id
stage = xport_input
brokers = localhost:9092
topic = RootOperKafkaTest
consumergroup = mycollectors
encoding = json

[kafkaBout]
type = kafka
key = path_and_id
stage = xport_output
brokers = localhost:9092
topic_metadata_template = topic_template_testB.txt
datachanneldepth = 1000
encoding = json
required_acks = local

[kafkaBin]
type = kafka
key = path_and_id
stage = xport_input
brokers = localhost:9092
topic = RouterInSpace
consumergroup = mycollectors
encoding = json

[kafkaCout]
type = kafka
key = path_and_id
stage = xport_output
brokers = localhost:9092
topic_metadata_template = topic_template_testC.txt
datachanneldepth = 1000
encoding = json

[kafkaCin]
type = kafka
key = path_and_id
stage = xport_input
brokers = localhost:9092
topic = RootOperKafkaTest_RouterInSpace
consumergroup = mycollectors
encoding = json

[kafkaDout]
type = kafka
key = path_and_id
stage = xport_output
brokers = localhost:9092
topic = fallback_to_topic
topic_metadata_template = topic_template_testBAD.txt
datachanneldepth = 1000
encoding = json
required_acks = commit

[kafkaDin]
type = kafka
key = path_and_id
stage = xport_input
brokers = localhost:9092
topic = fallback_to_topic
consumergroup = mycollectors
encoding = json
